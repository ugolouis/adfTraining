{
	"name": "9_nb_ECDS_EmergencyVisitData_Main_UpdatePart_1",
	"properties": {
		"folder": {
			"name": "create_source_tables/ECDS_spark_sql_notebooks"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "719c9c6a-f773-4737-9661-d0e748fe6fed"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\r\n",
					"from pyspark.sql.functions import col, when, coalesce, lit, current_timestamp, left, expr, datediff, year, to_date\r\n",
					"from delta.tables import DeltaTable\r\n",
					"from pyspark.sql.types import IntegerType\r\n",
					"\r\n",
					"# Define paths\r\n",
					"storage_account_name = \"synapsestr\"\r\n",
					"delta_container_name = \"nervecentre-delta\"\r\n",
					"main_table_path = f'abfss://{delta_container_name}@{storage_account_name}.dfs.core.windows.net/ECDS_EmergencyVisitData_Main'\r\n",
					"patient_visit_history_path = f'abfss://{delta_container_name}@{storage_account_name}.dfs.core.windows.net/SPB/PatientVisitHistoryData_Current'\r\n",
					"patient_data_path = f'abfss://{delta_container_name}@{storage_account_name}.dfs.core.windows.net/SPB/PatientData_Current'\r\n",
					"accommodation_type_path = f'abfss://{delta_container_name}@{storage_account_name}.dfs.core.windows.net/ECDS_Accomodation_Type'\r\n",
					"\r\n",
					"# Create SparkSession\r\n",
					"spark = SparkSession.builder.appName(\"ECDS_EmergencyVisitData_Main_Update\").getOrCreate()\r\n",
					"\r\n",
					"# Define custom function to strip characters\r\n",
					"def fn_StripCharacters(column, characters):\r\n",
					"    return expr(f\"regexp_replace({column}, '[^{characters}]', '')\")\r\n",
					"\r\n",
					"# Read source tables and register as temporary views\r\n",
					"spark.read.format(\"delta\").load(patient_visit_history_path).createOrReplaceTempView(\"patient_visit_history\")\r\n",
					"spark.read.format(\"delta\").load(patient_data_path).createOrReplaceTempView(\"patient_data\")\r\n",
					"spark.read.format(\"delta\").load(accommodation_type_path).createOrReplaceTempView(\"accommodation_type\")\r\n",
					"\r\n",
					"# Create source view using Spark SQL\r\n",
					"spark.sql(\"\"\"\r\n",
					"CREATE OR REPLACE TEMPORARY VIEW src_view AS\r\n",
					"SELECT\r\n",
					"    pev.visitarchiveid,\r\n",
					"    pev.visitid,\r\n",
					"    CAST(regexp_replace(pev.visitid, '[^0-9]', '') AS INT) AS Er_Visit_Id,\r\n",
					"    LEFT(COALESCE(pev.HN, pc.altnumber), 10) AS PATID_Extended,\r\n",
					"    'RXC00' AS Org_Code_PATID,\r\n",
					"    LEFT(pc.natlnumber, 10) AS NHS_Number,\r\n",
					"    CAST(pc.title AS STRING) AS PersonTitle,\r\n",
					"    LEFT(pc.firstName, 35) AS PersonGivenName,\r\n",
					"    LEFT(pc.lastName, 35) AS PersonFamilyName,\r\n",
					"    LEFT(pc.addressStreet, 35) AS AddressLine1,\r\n",
					"    LEFT(pc.addressArea, 35) AS AddressLine2,\r\n",
					"    LEFT(pc.addressCity, 35) AS AddressLine3,\r\n",
					"    LEFT(pc.addressCounty, 35) AS AddressLine4,\r\n",
					"    CAST(NULL AS STRING) AS AddressLine5,\r\n",
					"    LEFT(pc.addressPostCode, 8) AS Postcode,\r\n",
					"    CASE\r\n",
					"        WHEN pc.Gender = 'Male' THEN '1'\r\n",
					"        WHEN pc.Gender = 'Female' THEN '2'\r\n",
					"        ELSE '9'\r\n",
					"    END AS Gender,\r\n",
					"    pc.DOB,\r\n",
					"    LEFT(act.AccomodationTypeSNOMED, 18) AS Accomm_Status,\r\n",
					"    CASE\r\n",
					"        WHEN pev.ward LIKE 'HAS%' THEN 'RXC01'\r\n",
					"        ELSE 'RXC02'\r\n",
					"    END AS Site_Code_Of_Treatment,\r\n",
					"    pev.ward AS NervecenterWard,\r\n",
					"    pev.eventTime AS Arrival_Date_Time,\r\n",
					"    CAST(COALESCE(\r\n",
					"        YEAR(pev.eventTime) - YEAR(pc.DOB) - \r\n",
					"        CASE\r\n",
					"            WHEN (YEAR(pev.eventTime) - YEAR(pc.DOB)) * 365 + DATEDIFF(pev.eventTime, pc.DOB) % 365 < 0 THEN 1\r\n",
					"            ELSE 0\r\n",
					"        END,\r\n",
					"        999\r\n",
					"    ) AS STRING) AS Age_at_CDS_Activity_Date,\r\n",
					"    pev.EpisodeID\r\n",
					"FROM patient_visit_history pev\r\n",
					"LEFT JOIN patient_data pc ON pev.patientid = pc.patientid\r\n",
					"LEFT JOIN accommodation_type act ON pev.visitarchiveid = act.visitarchiveid\r\n",
					"WHERE pev.eventType = 'A' AND pev.source = 'L' AND pev.eventTime >= '2020-12-09'\r\n",
					"\"\"\")\r\n",
					"\r\n",
					"# Create a DeltaTable object for the target table\r\n",
					"target_table = DeltaTable.forPath(spark, main_table_path)\r\n",
					"target_table.toDF().createOrReplaceTempView(\"target_table\")\r\n",
					"\r\n",
					"# Perform the MERGE operation using Spark SQL\r\n",
					"merge_sql = \"\"\"\r\n",
					"MERGE INTO target_table AS tgt\r\n",
					"USING src_view AS src\r\n",
					"ON tgt.visitarchiveid = src.visitarchiveid\r\n",
					"WHEN MATCHED AND (\r\n",
					"    (COALESCE(src.visitid, 'X') <> COALESCE(tgt.visitid, 'X')) OR\r\n",
					"    (COALESCE(src.Er_Visit_ID, 0) <> COALESCE(tgt.Er_Visit_ID, 0)) OR\r\n",
					"    (COALESCE(src.Org_Code_PATID, 'X') <> COALESCE(tgt.Org_Code_PATID, 'X')) OR\r\n",
					"    (COALESCE(src.NHS_Number, 'X') <> COALESCE(tgt.NHS_Number, 'X')) OR\r\n",
					"    (COALESCE(src.PersonTitle, 'X') <> COALESCE(tgt.PersonTitle, 'X')) OR\r\n",
					"    (COALESCE(src.PersonGivenName, 'X') <> COALESCE(tgt.PersonGivenName, 'X')) OR\r\n",
					"    (COALESCE(src.PersonFamilyName, 'X') <> COALESCE(tgt.PersonFamilyName, 'X')) OR\r\n",
					"    (COALESCE(src.AddressLine1, 'X') <> COALESCE(tgt.AddressLine1, 'X')) OR\r\n",
					"    (COALESCE(src.AddressLine2, 'X') <> COALESCE(tgt.AddressLine2, 'X')) OR\r\n",
					"    (COALESCE(src.AddressLine3, 'X') <> COALESCE(tgt.AddressLine3, 'X')) OR\r\n",
					"    (COALESCE(src.AddressLine4, 'X') <> COALESCE(tgt.AddressLine4, 'X')) OR\r\n",
					"    (COALESCE(src.AddressLine5, 'X') <> COALESCE(tgt.AddressLine5, 'X')) OR\r\n",
					"    (COALESCE(src.Postcode, 'X') <> COALESCE(tgt.Postcode, 'X')) OR\r\n",
					"    (COALESCE(src.Gender, 'X') <> COALESCE(tgt.Gender, 'X')) OR\r\n",
					"    (COALESCE(src.DOB, DATE '1900-01-01') <> COALESCE(tgt.DOB, DATE '1900-01-01')) OR\r\n",
					"    (COALESCE(src.Accomm_Status, 'X') <> COALESCE(tgt.Accomm_Status, 'X')) OR\r\n",
					"    (COALESCE(src.Site_Code_Of_Treatment, 'X') <> COALESCE(tgt.Site_Code_Of_Treatment, 'X')) OR\r\n",
					"    (COALESCE(src.NervecenterWard, 'X') <> COALESCE(tgt.NervecenterWard, 'X')) OR\r\n",
					"    (COALESCE(src.Arrival_Date_Time, TIMESTAMP '1900-01-01 00:00:00') <> COALESCE(tgt.Arrival_Date_Time, TIMESTAMP '1900-01-01 00:00:00')) OR\r\n",
					"    (COALESCE(src.Age_at_CDS_Activity_Date, 'X') <> COALESCE(tgt.Age_at_CDS_Activity_Date, 'X')) OR\r\n",
					"    (COALESCE(src.EpisodeID, 'X') <> COALESCE(tgt.EpisodeID, 'X'))\r\n",
					")\r\n",
					"THEN UPDATE SET\r\n",
					"    visitid = src.visitid,\r\n",
					"    Er_Visit_ID = src.Er_Visit_ID,\r\n",
					"    Org_Code_PATID = src.Org_Code_PATID,\r\n",
					"    NHS_Number = src.NHS_Number,\r\n",
					"    PersonTitle = src.PersonTitle,\r\n",
					"    PersonFamilyName = src.PersonFamilyName,\r\n",
					"    PersonGivenName = src.PersonGivenName,\r\n",
					"    AddressLine1 = src.AddressLine1,\r\n",
					"    AddressLine2 = src.AddressLine2,\r\n",
					"    AddressLine3 = src.AddressLine3,\r\n",
					"    AddressLine4 = src.AddressLine4,\r\n",
					"    AddressLine5 = src.AddressLine5,\r\n",
					"    Postcode = src.Postcode,\r\n",
					"    Gender = src.Gender,\r\n",
					"    DOB = src.DOB,\r\n",
					"    Accomm_Status = src.Accomm_Status,\r\n",
					"    Site_Code_Of_Treatment = src.Site_Code_Of_Treatment,\r\n",
					"    NervecenterWard = src.NervecenterWard,\r\n",
					"    Arrival_Date_Time = src.Arrival_Date_Time,\r\n",
					"    Age_at_CDS_Activity_Date = src.Age_at_CDS_Activity_Date,\r\n",
					"    EpisodeID = src.EpisodeID,\r\n",
					"    AmendedOn = current_timestamp()\r\n",
					"WHEN NOT MATCHED THEN\r\n",
					"INSERT (\r\n",
					"    visitarchiveid,\r\n",
					"    visitid,\r\n",
					"    Er_Visit_ID,\r\n",
					"    PATID_Extended,\r\n",
					"    Org_Code_PATID,\r\n",
					"    NHS_Number,\r\n",
					"    PersonTitle,\r\n",
					"    PersonFamilyName,\r\n",
					"    PersonGivenName,\r\n",
					"    AddressLine1,\r\n",
					"    AddressLine2,\r\n",
					"    AddressLine3,\r\n",
					"    AddressLine4,\r\n",
					"    AddressLine5,\r\n",
					"    Postcode,\r\n",
					"    Gender,\r\n",
					"    DOB,\r\n",
					"    Accomm_Status,\r\n",
					"    Site_Code_Of_Treatment,\r\n",
					"    NervecenterWard,\r\n",
					"    Arrival_Date_Time,\r\n",
					"    Age_at_CDS_Activity_Date,\r\n",
					"    EpisodeID\r\n",
					")\r\n",
					"VALUES (\r\n",
					"    src.visitarchiveid,\r\n",
					"    src.visitid,\r\n",
					"    src.Er_Visit_ID,\r\n",
					"    src.PATID_Extended,\r\n",
					"    src.Org_Code_PATID,\r\n",
					"    src.NHS_Number,\r\n",
					"    src.PersonTitle,\r\n",
					"    src.PersonFamilyName,\r\n",
					"    src.PersonGivenName,\r\n",
					"    src.AddressLine1,\r\n",
					"    src.AddressLine2,\r\n",
					"    src.AddressLine3,\r\n",
					"    src.AddressLine4,\r\n",
					"    src.AddressLine5,\r\n",
					"    src.Postcode,\r\n",
					"    src.Gender,\r\n",
					"    src.DOB,\r\n",
					"    src.Accomm_Status,\r\n",
					"    src.Site_Code_Of_Treatment,\r\n",
					"    src.NervecenterWard,\r\n",
					"    src.Arrival_Date_Time,\r\n",
					"    src.Age_at_CDS_Activity_Date,\r\n",
					"    src.EpisodeID\r\n",
					")\r\n",
					"\"\"\"\r\n",
					"\r\n",
					"spark.sql(merge_sql)\r\n",
					"\r\n",
					"# Additional update for X numbers using Spark SQL\r\n",
					"spark.sql(\"\"\"\r\n",
					"MERGE INTO target_table AS tgt\r\n",
					"USING (\r\n",
					"    SELECT \r\n",
					"        t.visitarchiveid,\r\n",
					"        LEFT(COALESCE(pev.HN, pc.altnumber), 10) AS PATID_Extended\r\n",
					"    FROM target_table t\r\n",
					"    JOIN patient_visit_history pev ON t.visitarchiveid = pev.visitarchiveid\r\n",
					"    LEFT JOIN patient_data pc ON pev.patientid = pc.patientid\r\n",
					"    WHERE t.PATID_Extended IS NULL\r\n",
					") AS upd\r\n",
					"ON tgt.visitarchiveid = upd.visitarchiveid\r\n",
					"WHEN MATCHED THEN UPDATE SET\r\n",
					"    tgt.PATID_Extended = upd.PATID_Extended\r\n",
					"\"\"\")\r\n",
					"\r\n",
					"# Log the number of affected rows (optional)\r\n",
					"affected_rows = spark.sql(\"SELECT COUNT(*) as count FROM target_table\").collect()[0]['count']\r\n",
					"print(f\"Number of rows in the target table after update: {affected_rows}\")"
				],
				"execution_count": null
			}
		]
	}
}